import streamlit as st
import asyncio
import nest_asyncio
import json
import os

# nest_asyncio ì ìš©: ì´ë¯¸ ì‹¤í–‰ ì¤‘ì¸ ì´ë²¤íŠ¸ ë£¨í”„ ë‚´ì—ì„œ ì¤‘ì²© í˜¸ì¶œ í—ˆìš©
nest_asyncio.apply()

# ì „ì—­ ì´ë²¤íŠ¸ ë£¨í”„ ìƒì„± ë° ì¬ì‚¬ìš© (í•œë²ˆ ìƒì„±í•œ í›„ ê³„ì† ì‚¬ìš©)
if "event_loop" not in st.session_state:
    loop = asyncio.new_event_loop()
    st.session_state.event_loop = loop
    asyncio.set_event_loop(loop)

from langgraph.prebuilt import create_react_agent
from langchain_anthropic import ChatAnthropic
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage
from dotenv import load_dotenv
from langchain_mcp_adapters.client import MultiServerMCPClient
from langchain_teddynote.messages import astream_graph, random_uuid
from langchain_core.messages.ai import AIMessageChunk
from langchain_core.messages.tool import ToolMessage
from langgraph.checkpoint.memory import MemorySaver
from langchain_core.runnables import RunnableConfig

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ (.env íŒŒì¼ì—ì„œ API í‚¤ ë“±ì˜ ì„¤ì •ì„ ê°€ì ¸ì˜´)
load_dotenv(override=True)

# í˜ì´ì§€ ì„¤ì •: ì œëª©, ì•„ì´ì½˜, ë ˆì´ì•„ì›ƒ êµ¬ì„±
st.set_page_config(page_title="Agent with MCP Tools", page_icon="ğŸ§ ", layout="wide")

# ì‚¬ì´ë“œë°” ìµœìƒë‹¨ì— ì €ì ì •ë³´ ì¶”ê°€
st.sidebar.markdown("### âœï¸ Made by [í…Œë””ë…¸íŠ¸](https://youtube.com/c/teddynote) ğŸš€")
st.sidebar.divider()  # êµ¬ë¶„ì„  ì¶”ê°€

# --- ì‚¬ì´ë“œë°”: LLM ëª¨ë¸ ì„ íƒ ---
model_options = ["claude 3.7sonnet", "gpt-4o", "gemini-2.0", "Grok3", "Llamma3.3", "phoenix-1.0"]
selected_model = st.sidebar.selectbox("LLM ëª¨ë¸ ì„ íƒ", model_options, index=0, key="model_choice")
# ì§€ì›ë˜ì§€ ì•ŠëŠ” ëª¨ë¸ì— ëŒ€í•œ ê²½ê³  ë©”ì‹œì§€ í‘œì‹œ
if selected_model not in ["claude 3.7sonnet", "gpt-4o"]:
    st.sidebar.warning("âš ï¸ ì„ íƒí•œ ëª¨ë¸ì€ í˜„ì¬ ì§€ì›ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. Claude 3.7sonnet ë˜ëŠ” GPT-4oë§Œ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.")
# ëª¨ë¸ ì„ íƒ ë³€ê²½ ì‹œ ì„¸ì…˜ ì¬ì´ˆê¸°í™”
if "current_model" not in st.session_state:
    st.session_state.current_model = selected_model
elif st.session_state.current_model != selected_model:
    st.session_state.current_model = selected_model
    st.session_state.session_initialized = False
    st.session_state.agent = None
    st.session_state.mcp_client = None

# ê¸°ì¡´ í˜ì´ì§€ ì œëª© ë° ì„¤ëª…
st.title("ğŸ¤– Agent with MCP Tools")
st.markdown("âœ¨ MCP ë„êµ¬ë¥¼ í™œìš©í•œ ReAct ì—ì´ì „íŠ¸ì—ê²Œ ì§ˆë¬¸í•´ë³´ì„¸ìš”.")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "session_initialized" not in st.session_state:
    st.session_state.session_initialized = False
    st.session_state.agent = None
    st.session_state.history = []
    st.session_state.mcp_client = None
    st.session_state.timeout_seconds = 120  # ì‘ë‹µ ìƒì„± ì œí•œ ì‹œê°„(ì´ˆ)

if "thread_id" not in st.session_state:
    st.session_state.thread_id = random_uuid()

# --- í•¨ìˆ˜ ì •ì˜ ë¶€ë¶„ ---

async def cleanup_mcp_client():
    """ê¸°ì¡´ MCP í´ë¼ì´ì–¸íŠ¸ë¥¼ ì•ˆì „í•˜ê²Œ ì¢…ë£Œí•©ë‹ˆë‹¤."""
    if "mcp_client" in st.session_state and st.session_state.mcp_client is not None:
        try:
            await st.session_state.mcp_client.__aexit__(None, None, None)
            st.session_state.mcp_client = None
        except Exception:
            # MCP í´ë¼ì´ì–¸íŠ¸ ì¢…ë£Œ ì¤‘ ë°œìƒí•œ ì˜¤ë¥˜ëŠ” ë¬´ì‹œ (í•„ìš” ì‹œ ë¡œê·¸ ì²˜ë¦¬ ê°€ëŠ¥)
            pass

def print_message():
    """í˜„ì¬ê¹Œì§€ì˜ ëŒ€í™” ê¸°ë¡ì„ í™”ë©´ì— ì¶œë ¥í•©ë‹ˆë‹¤."""
    i = 0
    while i < len(st.session_state.history):
        message = st.session_state.history[i]
        if message["role"] == "user":
            st.chat_message("user").markdown(message["content"])
            i += 1
        elif message["role"] == "assistant":
            # Assistant ë©”ì‹œì§€ ì¶œë ¥ ì»¨í…Œì´ë„ˆ ìƒì„±
            with st.chat_message("assistant"):
                st.markdown(message["content"])
                # ë°”ë¡œ ë‹¤ìŒ ë©”ì‹œì§€ê°€ ë„êµ¬ í˜¸ì¶œ ì •ë³´ì¸ì§€ í™•ì¸
                if i + 1 < len(st.session_state.history) and st.session_state.history[i + 1]["role"] == "assistant_tool":
                    # ë„êµ¬ í˜¸ì¶œ ì •ë³´ëŠ” expanderë¡œ ê°™ì€ ì»¨í…Œì´ë„ˆ ë‚´ì— í‘œì‹œ
                    with st.expander("ğŸ”§ ë„êµ¬ í˜¸ì¶œ ì •ë³´", expanded=False):
                        st.markdown(st.session_state.history[i + 1]["content"])
                    i += 2  # ë©”ì‹œì§€ 2ê°œ(user ì§ˆë¬¸+tool ì •ë³´)ë¥¼ í•œ ë²ˆì— ì²˜ë¦¬
                else:
                    i += 1
        else:
            # "assistant_tool" ì—­í• ì˜ ë©”ì‹œì§€ëŠ” ìœ„ì—ì„œ í•¨ê»˜ ì²˜ë¦¬í•˜ë¯€ë¡œ ê±´ë„ˆëœ€
            i += 1

def get_streaming_callback(text_placeholder, tool_placeholder):
    """
    ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„±ì„ ì²˜ë¦¬í•˜ëŠ” ì½œë°± í•¨ìˆ˜ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    - text_placeholder: ì‹¤ì‹œê°„ ìƒì„±ë˜ëŠ” í…ìŠ¤íŠ¸ ì‘ë‹µ í‘œì‹œìš©
    - tool_placeholder: ì‹¤ì‹œê°„ ìƒì„±ë˜ëŠ” ë„êµ¬ í˜¸ì¶œ ì •ë³´ í‘œì‹œìš©
    """
    accumulated_text = []
    accumulated_tool = []

    def callback_func(message: dict):
        nonlocal accumulated_text, accumulated_tool
        content = message.get("content", None)
        if isinstance(content, AIMessageChunk):
            chunk = content.content
            if isinstance(chunk, list) and len(chunk) > 0:
                part = chunk[0]
                if part["type"] == "text":
                    # í…ìŠ¤íŠ¸ ì‘ë‹µ ì¡°ê°
                    accumulated_text.append(part["text"])
                    text_placeholder.markdown("".join(accumulated_text))
                elif part["type"] == "tool_use":
                    # ë„êµ¬ í˜¸ì¶œ ì¡°ê°
                    if "partial_json" in part:
                        accumulated_tool.append(part["partial_json"])
                    else:
                        tool_call_chunk = content.tool_call_chunks[0]
                        accumulated_tool.append("\n```json\n" + str(tool_call_chunk) + "\n```\n")
                    with tool_placeholder.expander("ğŸ”§ ë„êµ¬ í˜¸ì¶œ ì •ë³´", expanded=True):
                        st.markdown("".join(accumulated_tool))
        elif isinstance(content, ToolMessage):
            # ìµœì¢… ë„êµ¬ í˜¸ì¶œ ê²°ê³¼ ë©”ì‹œì§€
            accumulated_tool.append("\n```json\n" + str(content.content) + "\n```\n")
            with tool_placeholder.expander("ğŸ”§ ë„êµ¬ í˜¸ì¶œ ì •ë³´", expanded=True):
                st.markdown("".join(accumulated_tool))
        return None

    return callback_func, accumulated_text, accumulated_tool

async def process_query(query, text_placeholder, tool_placeholder, timeout_seconds=60):
    """ì‚¬ìš©ì ì§ˆë¬¸ì„ ë°›ì•„ ì—ì´ì „íŠ¸ì˜ ì‘ë‹µì„ ìƒì„±í•˜ê³  ë°˜í™˜í•©ë‹ˆë‹¤."""
    try:
        if st.session_state.agent:
            # ìŠ¤íŠ¸ë¦¬ë° ì½œë°± ë° ëˆ„ì  ë²„í¼ ì´ˆê¸°í™”
            streaming_callback, accumulated_text, accumulated_tool = get_streaming_callback(text_placeholder, tool_placeholder)
            try:
                response = await asyncio.wait_for(
                    astream_graph(
                        st.session_state.agent,
                        {"messages": [HumanMessage(content=query)]},
                        callback=streaming_callback,
                        config=RunnableConfig(recursion_limit=100, thread_id=st.session_state.thread_id),
                    ),
                    timeout=timeout_seconds,
                )
            except asyncio.TimeoutError:
                error_msg = f"â±ï¸ ìš”ì²­ ì‹œê°„ì´ {timeout_seconds}ì´ˆë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. ë‚˜ì¤‘ì— ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."
                return {"error": error_msg}, error_msg, ""
            # ìµœì¢… ì‘ë‹µ ì·¨í•©
            final_text = "".join(accumulated_text)
            final_tool = "".join(accumulated_tool)
            return response, final_text, final_tool
        else:
            return ({"error": "ğŸš« ì—ì´ì „íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}, "ğŸš« ì—ì´ì „íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.", "")
    except Exception as e:
        import traceback
        error_msg = f"âŒ ì¿¼ë¦¬ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\n{traceback.format_exc()}"
        return {"error": error_msg}, error_msg, ""

async def initialize_session(mcp_config=None):
    """
    MCP í´ë¼ì´ì–¸íŠ¸ì™€ LangChain ì—ì´ì „íŠ¸ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
    - mcp_config: MCP ë„êµ¬ ì„¤ì • (JSON dict). Noneì´ë©´ ê¸°ë³¸ ì›ê²© ì„¤ì • ì‚¬ìš©.
    ë°˜í™˜: ì´ˆê¸°í™” ì„±ê³µ(bool)
    """
    try:
        with st.spinner("ğŸ”„ MCP ì„œë²„ì— ì—°ê²° ì¤‘..."):
            # ê¸°ì¡´ MCP í´ë¼ì´ì–¸íŠ¸ ì¢…ë£Œ ì²˜ë¦¬
            await cleanup_mcp_client()
            if mcp_config is None:
                # ê¸°ë³¸ ì„¤ì •: ì›ê²© MCP ì„œë²„(SSE) Weather íˆ´
                mcp_config = {
                    "weather": {
                        "url": "http://3.35.28.26:8005/sse",
                        "transport": "sse",
                    }
                }
            # MCP ë©€í‹°ì„œë²„ í´ë¼ì´ì–¸íŠ¸ ìƒì„± ë° ì ‘ì†
            client = MultiServerMCPClient(mcp_config)
            await client.__aenter__()
            tools = client.get_tools()
            st.session_state.tool_count = len(tools)
            st.session_state.mcp_client = client

            # LLM ëª¨ë¸ ì„ íƒì— ë”°ë¼ ì ì ˆí•œ LangChain Chat ê°ì²´ ìƒì„±
            model_choice = st.session_state.get("model_choice", "claude 3.7sonnet")
            if model_choice == "claude 3.7sonnet":
                model = ChatAnthropic(model="claude-3-7-sonnet-latest", temperature=0.1, max_tokens=20000)
            elif model_choice == "gpt-4o":
                model = ChatOpenAI(model="gpt-4o", temperature=0.1, max_tokens=20000)
            else:
                # ì§€ì›ë˜ì§€ ì•ŠëŠ” ëª¨ë¸ì¸ ê²½ìš° ì´ˆê¸°í™” ì‹¤íŒ¨ ì²˜ë¦¬
                st.error("ğŸš« ì„ íƒí•œ LLM ëª¨ë¸ì€ ì§€ì›ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ëª¨ë¸ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
                return False

            # ReAct ì—ì´ì „íŠ¸ ìƒì„± (LangGraph)
            agent = create_react_agent(
                model,
                tools,
                checkpointer=MemorySaver(),
                prompt="Use your tools to answer the question. Answer in Korean.",
            )
            st.session_state.agent = agent
            st.session_state.session_initialized = True
            return True
    except Exception as e:
        st.error(f"âŒ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        st.error(traceback.format_exc())
        return False

# --- ì‚¬ì´ë“œë°”: MCP ë„êµ¬ ì¶”ê°€ ---
with st.sidebar.expander("ë„êµ¬ ì¶”ê°€", expanded=False):
    default_config = """{
  "weather": {
    "url": "http://3.35.28.26:8005/sse",
    "transport": "sse"
  }
}"""
    # session_stateì— pending ì„¤ì •ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©
    if "pending_mcp_config" not in st.session_state:
        try:
            st.session_state.pending_mcp_config = json.loads(
                st.session_state.get("mcp_config_text", default_config)
            )
        except Exception as e:
            st.error(f"ì´ˆê¸° pending config ì„¤ì • ì‹¤íŒ¨: {e}")

    st.subheader("ê°œë³„ ë„êµ¬ ì¶”ê°€")
    st.markdown(
        """
    **í•˜ë‚˜ì˜ ë„êµ¬**ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ì…ë ¥í•˜ì„¸ìš”:
    
    ```json
    {
      "ë„êµ¬ì´ë¦„": {
        "command": "ì‹¤í–‰ ëª…ë ¹ì–´",
        "args": ["ì¸ì1", "ì¸ì2", ...],
        "transport": "stdio"
      }
    }
    ```    
    âš ï¸ **ì¤‘ìš”**: JSONì„ ë°˜ë“œì‹œ ì¤‘ê´„í˜¸(`{}`)ë¡œ ê°ì‹¸ì•¼ í•©ë‹ˆë‹¤.
    """
    )

    # ì˜ˆì‹œ JSON (GitHub íˆ´ ì˜ˆì œ)
    example_json = {
        "github": {
            "command": "npx",
            "args": [
                "-y",
                "@smithery/cli@latest",
                "run",
                "@smithery-ai/github",
                "--config",
                '{"githubPersonalAccessToken":"your_token_here"}',
            ],
            "transport": "stdio",
        }
    }
    default_text = json.dumps(example_json, indent=2, ensure_ascii=False)
    new_tool_json = st.text_area("ë„êµ¬ JSON", default_text, height=250)

    # "ë„êµ¬ ì¶”ê°€" ë²„íŠ¼ ì²˜ë¦¬
    if st.button("ë„êµ¬ ì¶”ê°€", type="primary", key="add_tool_button", use_container_width=True):
        try:
            # JSON ë¬¸ìì—´ ê¸°ë³¸ ê²€ì¦
            if not new_tool_json.strip().startswith("{") or not new_tool_json.strip().endswith("}"):
                st.error("JSONì€ ì¤‘ê´„í˜¸({})ë¡œ ì‹œì‘í•˜ê³  ëë‚˜ì•¼ í•©ë‹ˆë‹¤.")
                st.markdown('ì˜¬ë°”ë¥¸ í˜•ì‹: `{ "ë„êµ¬ì´ë¦„": { ... } }`')
            else:
                parsed_tool = json.loads(new_tool_json)
                # í˜¹ì‹œ ìµœìƒìœ„ì— "mcpServers" í‚¤ê°€ ìˆìœ¼ë©´ ë‚´ë¶€ ë‚´ìš©ìœ¼ë¡œ ëŒ€ì²´
                if "mcpServers" in parsed_tool:
                    parsed_tool = parsed_tool["mcpServers"]
                    st.info("'mcpServers' í˜•ì‹ì´ ê°ì§€ë˜ì–´ ë‚´ë¶€ ë„êµ¬ ì„¤ì •ìœ¼ë¡œ ë³€í™˜í–ˆìŠµë‹ˆë‹¤.")
                if len(parsed_tool) == 0:
                    st.error("ìµœå°‘ í•˜ë‚˜ ì´ìƒì˜ ë„êµ¬ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                else:
                    success_tools = []
                    for tool_name, tool_config in parsed_tool.items():
                        # URL ì¡´ì¬ ì‹œ transportë¥¼ "sse"ë¡œ ê°•ì œ
                        if "url" in tool_config:
                            tool_config["transport"] = "sse"
                            st.info(f"'{tool_name}' ë„êµ¬ì— URLì´ ìˆì–´ transportë¥¼ 'sse'ë¡œ ì„¤ì •í–ˆìŠµë‹ˆë‹¤.")
                        elif "transport" not in tool_config:
                            tool_config["transport"] = "stdio"  # transport ëˆ„ë½ ì‹œ ê¸°ë³¸ "stdio"
                        # í•„ìˆ˜ í•„ë“œ ê²€ì¦
                        if "command" not in tool_config and "url" not in tool_config:
                            st.error(f"'{tool_name}' ì„¤ì •ì— 'command' ë˜ëŠ” 'url' í•„ë“œê°€ í•„ìš”í•©ë‹ˆë‹¤.")
                        elif "command" in tool_config and "args" not in tool_config:
                            st.error(f"'{tool_name}' ì„¤ì •ì— 'args' í•„ë“œê°€ í•„ìš”í•©ë‹ˆë‹¤.")
                        elif "command" in tool_config and not isinstance(tool_config["args"], list):
                            st.error(f"'{tool_name}'ì˜ 'args'ëŠ” ë¦¬ìŠ¤íŠ¸ í˜•ì‹ì´ì–´ì•¼ í•©ë‹ˆë‹¤.")
                        else:
                            # pending ì„¤ì •ì— ë„êµ¬ ì¶”ê°€
                            st.session_state.pending_mcp_config[tool_name] = tool_config
                            success_tools.append(tool_name)
                    # ì¶”ê°€ ì„±ê³µ ì•Œë¦¼
                    if success_tools:
                        if len(success_tools) == 1:
                            st.success(f"{success_tools[0]} ë„êµ¬ê°€ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤. ì ìš©í•˜ë ¤ë©´ 'ë„êµ¬ ì„¤ì • ì ìš©' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
                        else:
                            tool_list = ", ".join(success_tools)
                            st.success(f"ì´ {len(success_tools)}ê°œ ë„êµ¬({tool_list})ê°€ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤. ì ìš©í•˜ë ¤ë©´ 'ë„êµ¬ ì„¤ì • ì ìš©' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
        except json.JSONDecodeError as e:
            st.error(f"JSON íŒŒì‹± ì—ëŸ¬: {e}")
            st.markdown(
                """
            **ìˆ˜ì • ë°©ë²•**:  
            1. JSON í˜•ì‹ì´ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•˜ì„¸ìš”.  
            2. ëª¨ë“  í‚¤ì™€ ë¬¸ìì—´ ê°’ì„ í°ë”°ì˜´í‘œ(")ë¡œ ê°ì‹¸ì•¼ í•©ë‹ˆë‹¤.  
            3. ë¬¸ìì—´ ë‚´ì— í°ë”°ì˜´í‘œë¥¼ í¬í•¨í•´ì•¼ í•œë‹¤ë©´ `\"`ì²˜ëŸ¼ ì´ìŠ¤ì¼€ì´í”„ ì²˜ë¦¬ë¥¼ í•´ì•¼ í•©ë‹ˆë‹¤.
            """
            )
        except Exception as e:
            st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")

    st.divider()
    st.subheader("í˜„ì¬ ë„êµ¬ ì„¤ì • (ì½ê¸° ì „ìš©)")
    st.code(json.dumps(st.session_state.pending_mcp_config, indent=2, ensure_ascii=False))

# --- ë“±ë¡ëœ ë„êµ¬ ëª©ë¡ ë° ì‚­ì œ ---
with st.sidebar.expander("ë“±ë¡ëœ ë„êµ¬ ëª©ë¡", expanded=True):
    try:
        pending_config = st.session_state.pending_mcp_config
    except Exception:
        st.error("ìœ íš¨í•œ MCP ë„êµ¬ ì„¤ì •ì´ ì•„ë‹™ë‹ˆë‹¤.")
    else:
        for tool_name in list(pending_config.keys()):
            col1, col2 = st.columns([8, 2])
            col1.markdown(f"- **{tool_name}**")
            if col2.button("ì‚­ì œ", key=f"delete_{tool_name}"):
                del st.session_state.pending_mcp_config[tool_name]
                st.success(f"{tool_name} ë„êµ¬ê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤. ì ìš©í•˜ë ¤ë©´ 'ë„êµ¬ ì„¤ì • ì ìš©' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")

with st.sidebar:
    # "ë„êµ¬ ì„¤ì • ì ìš©" ë²„íŠ¼: pending ì„¤ì •ì„ ì‹¤ì œ ë°˜ì˜í•˜ì—¬ ì¬ì´ˆê¸°í™”
    if st.button("ë„êµ¬ ì„¤ì • ì ìš©", key="apply_button", type="primary", use_container_width=True):
        apply_status = st.empty()
        with apply_status.container():
            st.warning("ğŸ”„ ë³€ê²½ì‚¬í•­ì„ ì ìš©í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”...")
            progress_bar = st.progress(0)
            # ìƒˆë¡œìš´ ì„¤ì •ì„ ì„¸ì…˜ ìƒíƒœì— ì €ì¥
            st.session_state.mcp_config_text = json.dumps(st.session_state.pending_mcp_config, indent=2, ensure_ascii=False)
            # ì„¸ì…˜ ì¬ì´ˆê¸°í™” í”Œë˜ê·¸ ì„¤ì •
            st.session_state.session_initialized = False
            st.session_state.agent = None
            progress_bar.progress(30)
            # ì—ì´ì „íŠ¸ ì¬ìƒì„±
            success = st.session_state.event_loop.run_until_complete(initialize_session(st.session_state.pending_mcp_config))
            progress_bar.progress(100)
            if success:
                st.success("âœ… ìƒˆë¡œìš´ MCP ë„êµ¬ ì„¤ì •ì´ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤.")
            else:
                st.error("âŒ ìƒˆë¡œìš´ MCP ë„êµ¬ ì„¤ì • ì ìš©ì— ì‹¤íŒ¨í•˜ì˜€ìŠµë‹ˆë‹¤.")
        st.rerun()  # í˜ì´ì§€ ì¬ì‹¤í–‰

# --- ì´ˆê¸° ì„¸ì…˜ ìë™ ì´ˆê¸°í™” ---
if not st.session_state.session_initialized:
    st.info("ğŸ”„ MCP ì„œë²„ì™€ ì—ì´ì „íŠ¸ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”...")
    success = st.session_state.event_loop.run_until_complete(initialize_session())
    if success:
        st.success(f"âœ… ì´ˆê¸°í™” ì™„ë£Œ! {st.session_state.tool_count}ê°œì˜ ë„êµ¬ê°€ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
    else:
        # ëª¨ë¸ ë¯¸ì§€ì›ìœ¼ë¡œ ì‹¤íŒ¨í•œ ê²½ìš°ì™€ ê¸°íƒ€ ì˜¤ë¥˜ êµ¬ë¶„
        if st.session_state.get("model_choice") not in ["claude 3.7sonnet", "gpt-4o"]:
            st.error("âŒ ì„ íƒí•œ LLM ëª¨ë¸ì€ í˜„ì¬ ì§€ì›ë  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì§€ì›ë˜ëŠ” ëª¨ë¸ë¡œ ë³€ê²½í•´ì£¼ì„¸ìš”.")
        else:
            st.error("âŒ ì´ˆê¸°í™”ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨í•´ ì£¼ì„¸ìš”.")

# --- ëŒ€í™” ê¸°ë¡ ì¶œë ¥ ---
print_message()

# --- ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬ ---
user_query = st.chat_input("ğŸ’¬ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”")
if user_query:
    if st.session_state.session_initialized:
        st.chat_message("user").markdown(user_query)
        with st.chat_message("assistant"):
            tool_placeholder = st.empty()
            text_placeholder = st.empty()
            # ë¹„ë™ê¸° ì—ì´ì „íŠ¸ ì‘ë‹µ ìƒì„±
            resp, final_text, final_tool = st.session_state.event_loop.run_until_complete(
                process_query(user_query, text_placeholder, tool_placeholder, st.session_state.timeout_seconds)
            )
            # ì—ëŸ¬ ë°œìƒ ì‹œ ì—ëŸ¬ ë©”ì‹œì§€ í‘œì‹œ
            if isinstance(resp, dict) and resp.get("error"):
                st.markdown(final_text)
            else:
                # ìµœì¢… ì‘ë‹µ ì¶œë ¥
                st.markdown(final_text)
    else:
        st.error("ğŸš« ì—ì´ì „íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì¢Œì¸¡ì—ì„œ ì„¤ì •ì„ í™•ì¸í•˜ê³  ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")
